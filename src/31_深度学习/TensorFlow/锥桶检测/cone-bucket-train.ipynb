{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"锥桶识别模型训练.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOd1fDDMqDrmCCnrq/kTc3n"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"hS8c74aDyC5p"},"source":["file: cone-bucket-train.ipynb  \n","site: github.com/IYATT-yx/learning  \n","describe: 锥桶检测迁移学习训练  \n","\n","该笔记本可直接在 Google Colaboratory 上运行，运行前请将本笔记本文件及 cone-bucket.tar.gz （锥桶图片和标注数据）和 generate_tfrecord.py (xml 标注转 tf 数据）拷贝到 Google Drive 上，设置 GPU 加速然后运行本笔记本。  \n","\n","Copyright (C) 2021 IYATT-yx (Zhao Hongfei, 赵洪飞)，2514374431@qq.com\n","This program is free software: you can redistribute it and/or modify\n","it under the terms of the GNU Affero General Public License as published\n","by the Free Software Foundation, either version 3 of the License, or\n","(at your option) any later version.\n","This program is distributed in the hope that it will be useful,\n","but WITHOUT ANY WARRANTY; without even the implied warranty of\n","MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n","GNU Affero General Public License for more details.\n","You should have received a copy of the GNU Affero General Public License\n","along with this program.  If not, see <https://www.gnu.org/licenses/>."]},{"cell_type":"markdown","metadata":{"id":"Zqq9MvYSrDFO"},"source":["## 环境准备"]},{"cell_type":"code","metadata":{"id":"le0AsFq-oXQD","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1635211715121,"user_tz":-480,"elapsed":25420,"user":{"displayName":"yx IYATT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjkWQveQ9aeFabkZ0xN-od5GWsZF5pnqb-LIQcm=s64","userId":"12018810969794285660"}},"outputId":"207e7872-d8a3-4595-d479-9f5a462ae072"},"source":["!pip3 install opencv-python==4.5.3.56 tensorflow==2.6.0 matplotlib==3.4.3 protobuf==3.18.0 google==3.0.0"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting opencv-python==4.5.3.56\n","  Downloading opencv_python-4.5.3.56-cp37-cp37m-manylinux2014_x86_64.whl (49.9 MB)\n","\u001b[K     |████████████████████████████████| 49.9 MB 18 kB/s \n","\u001b[?25hRequirement already satisfied: tensorflow==2.6.0 in /usr/local/lib/python3.7/dist-packages (2.6.0)\n","Collecting matplotlib==3.4.3\n","  Downloading matplotlib-3.4.3-cp37-cp37m-manylinux1_x86_64.whl (10.3 MB)\n","\u001b[K     |████████████████████████████████| 10.3 MB 24.7 MB/s \n","\u001b[?25hCollecting protobuf==3.18.0\n","  Downloading protobuf-3.18.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n","\u001b[K     |████████████████████████████████| 1.1 MB 28.8 MB/s \n","\u001b[?25hCollecting google==3.0.0\n","  Downloading google-3.0.0-py2.py3-none-any.whl (45 kB)\n","\u001b[K     |████████████████████████████████| 45 kB 3.1 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python==4.5.3.56) (1.19.5)\n","Requirement already satisfied: tensorflow-estimator~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6.0) (2.6.0)\n","Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6.0) (1.12)\n","Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6.0) (1.12.1)\n","Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6.0) (1.1.2)\n","Requirement already satisfied: keras~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6.0) (2.6.0)\n","Requirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6.0) (3.1.0)\n","Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6.0) (0.37.0)\n","Requirement already satisfied: clang~=5.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6.0) (5.0)\n","Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6.0) (0.2.0)\n","Requirement already satisfied: grpcio<2.0,>=1.37.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6.0) (1.41.0)\n","Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6.0) (1.6.3)\n","Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6.0) (1.1.0)\n","Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6.0) (2.6.0)\n","Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6.0) (0.12.0)\n","Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6.0) (3.3.0)\n","Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6.0) (3.7.4.3)\n","Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6.0) (1.15.0)\n","Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6.0) (0.4.0)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.4.3) (2.8.2)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.4.3) (1.3.2)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.4.3) (7.1.2)\n","Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.4.3) (2.4.7)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.4.3) (0.10.0)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from google==3.0.0) (4.6.3)\n","Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tensorflow==2.6.0) (1.5.2)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.6.0) (0.4.6)\n","Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.6.0) (1.35.0)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.6.0) (2.23.0)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.6.0) (57.4.0)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.6.0) (1.0.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.6.0) (3.3.4)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.6.0) (0.6.1)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.6.0) (1.8.0)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow==2.6.0) (4.2.4)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow==2.6.0) (0.2.8)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow==2.6.0) (4.7.2)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow==2.6.0) (1.3.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow==2.6.0) (4.8.1)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow==2.6.0) (0.4.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.6.0) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.6.0) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.6.0) (2021.5.30)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.6.0) (3.0.4)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow==2.6.0) (3.1.1)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard~=2.6->tensorflow==2.6.0) (3.6.0)\n","\u001b[33mWARNING: The candidate selected for download or install is a yanked version: 'protobuf' candidate (version 3.18.0 at https://files.pythonhosted.org/packages/75/dc/a90a5bfc608ad894b636904d6efff943a85e48a5c6466ccc8e3f73a214f2/protobuf-3.18.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl#sha256=877664b1b8d1e23553634f625e4e12aae4ff16cbbef473f8118c239d478f422a (from https://pypi.org/simple/protobuf/))\n","Reason for being yanked: This version claims to support Python 2 but does not\u001b[0m\n","Installing collected packages: protobuf, opencv-python, matplotlib, google\n","  Attempting uninstall: protobuf\n","    Found existing installation: protobuf 3.17.3\n","    Uninstalling protobuf-3.17.3:\n","      Successfully uninstalled protobuf-3.17.3\n","  Attempting uninstall: opencv-python\n","    Found existing installation: opencv-python 4.1.2.30\n","    Uninstalling opencv-python-4.1.2.30:\n","      Successfully uninstalled opencv-python-4.1.2.30\n","  Attempting uninstall: matplotlib\n","    Found existing installation: matplotlib 3.2.2\n","    Uninstalling matplotlib-3.2.2:\n","      Successfully uninstalled matplotlib-3.2.2\n","  Attempting uninstall: google\n","    Found existing installation: google 2.0.3\n","    Uninstalling google-2.0.3:\n","      Successfully uninstalled google-2.0.3\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n","Successfully installed google-3.0.0 matplotlib-3.4.3 opencv-python-4.5.3.56 protobuf-3.18.0\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["google","matplotlib","mpl_toolkits"]}}},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"cL4dhO27rGsb"},"source":["## 资源路径设置"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gN45_B27qXhC","executionInfo":{"status":"ok","timestamp":1635211736376,"user_tz":-480,"elapsed":21262,"user":{"displayName":"yx IYATT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjkWQveQ9aeFabkZ0xN-od5GWsZF5pnqb-LIQcm=s64","userId":"12018810969794285660"}},"outputId":"f893d633-7aed-4d57-f88f-eb09528e677a"},"source":["# 挂载谷歌云盘\n","from google.colab import drive\n","drive.mount('/content/temp', force_remount=True)"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/temp\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5IwUB8QVsqYv","executionInfo":{"status":"ok","timestamp":1635211737321,"user_tz":-480,"elapsed":950,"user":{"displayName":"yx IYATT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjkWQveQ9aeFabkZ0xN-od5GWsZF5pnqb-LIQcm=s64","userId":"12018810969794285660"}},"outputId":"43f04335-856e-400f-e977-6afa99b5f648"},"source":["# 将资源文件拷贝到 Colab\n","!cp temp/MyDrive/锥桶识别/cone-bucket.tar.gz .\n","!cp temp/MyDrive/锥桶识别/generate_tfrecord.py .\n","!ls"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["cone-bucket.tar.gz  generate_tfrecord.py  sample_data  temp\n"]}]},{"cell_type":"code","metadata":{"id":"10-RYuqptTcQ","executionInfo":{"status":"ok","timestamp":1635211737322,"user_tz":-480,"elapsed":15,"user":{"displayName":"yx IYATT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjkWQveQ9aeFabkZ0xN-od5GWsZF5pnqb-LIQcm=s64","userId":"12018810969794285660"}}},"source":["PRETRAINED_MODEL_NAME = 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8'\n","PRETRAINED_MODEL_URL = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz'\n","TF_RECORD_SCRIPT_NAME = 'generate_tfrecord.py'\n","LABEL_MAP_NAME = 'label_map.pbtxt'"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"jWNUj006uh9b","executionInfo":{"status":"ok","timestamp":1635211737323,"user_tz":-480,"elapsed":14,"user":{"displayName":"yx IYATT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjkWQveQ9aeFabkZ0xN-od5GWsZF5pnqb-LIQcm=s64","userId":"12018810969794285660"}}},"source":["paths = {\n","    'WORKSPACE_PATH': 'work-temp/workspace',\n","    'SCRIPTS_PATH': 'work-temp/scripts',\n","    'APIMODEL_PATH': 'work-temp/models',\n","    'ANNOTATION_PATH': 'work-temp/workspace/annotations',\n","    'IMAGE_PATH': 'work-temp/workspace/images',\n","    'MODEL_PATH': 'work-temp/workspace/models',\n","    'PRETRAINED_MODEL_PATH': 'work-temp/workspace/pretrained_models',\n","    'CHECKPOINT_PATH': 'work-temp/workspace/models',  \n","    'PROTOC_PATH': 'work-temp/protoc'\n"," }"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"M5CCJicoyJBl","executionInfo":{"status":"ok","timestamp":1635211737323,"user_tz":-480,"elapsed":12,"user":{"displayName":"yx IYATT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjkWQveQ9aeFabkZ0xN-od5GWsZF5pnqb-LIQcm=s64","userId":"12018810969794285660"}}},"source":["files = {\n","    'PIPELINE_CONFIG': 'work-temp/workspace/models/' + 'pipeline.config',\n","    'TF_RECORD_SCRIPT': paths['SCRIPTS_PATH'] + '/' + TF_RECORD_SCRIPT_NAME,\n","    'LABELMAP': paths['ANNOTATION_PATH'] + '/' + LABEL_MAP_NAME\n","}"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lwTlDkgzywSU","executionInfo":{"status":"ok","timestamp":1635211745209,"user_tz":-480,"elapsed":7896,"user":{"displayName":"yx IYATT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjkWQveQ9aeFabkZ0xN-od5GWsZF5pnqb-LIQcm=s64","userId":"12018810969794285660"}},"outputId":"d57fc40e-725a-4cec-f562-8d3ce9f68d35"},"source":["# 创建工作路径\n","import os\n","for path in paths.values():\n","    if not os.path.exists(path):\n","        !mkdir -p {path}\n","!apt install tree\n","!tree work-temp"],"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","The following NEW packages will be installed:\n","  tree\n","0 upgraded, 1 newly installed, 0 to remove and 37 not upgraded.\n","Need to get 40.7 kB of archives.\n","After this operation, 105 kB of additional disk space will be used.\n","Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 tree amd64 1.7.0-5 [40.7 kB]\n","Fetched 40.7 kB in 0s (104 kB/s)\n","Selecting previously unselected package tree.\n","(Reading database ... 155047 files and directories currently installed.)\n","Preparing to unpack .../tree_1.7.0-5_amd64.deb ...\n","Unpacking tree (1.7.0-5) ...\n","Setting up tree (1.7.0-5) ...\n","Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n","work-temp\n","├── models\n","├── protoc\n","├── scripts\n","└── workspace\n","    ├── annotations\n","    ├── images\n","    ├── models\n","    └── pretrained_models\n","\n","8 directories, 0 files\n"]}]},{"cell_type":"markdown","metadata":{"id":"l81zyTCeziyb"},"source":["## 获取预训练模型及安装 ob"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aff9njs2zrv3","executionInfo":{"status":"ok","timestamp":1635211749433,"user_tz":-480,"elapsed":4245,"user":{"displayName":"yx IYATT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjkWQveQ9aeFabkZ0xN-od5GWsZF5pnqb-LIQcm=s64","userId":"12018810969794285660"}},"outputId":"064639c7-2791-4a66-a1dc-a9a96fc93b21"},"source":["!git clone https://github.com/tensorflow/models {paths['APIMODEL_PATH']} --depth=1"],"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'work-temp/models'...\n","remote: Enumerating objects: 3023, done.\u001b[K\n","remote: Counting objects: 100% (3023/3023), done.\u001b[K\n","remote: Compressing objects: 100% (2552/2552), done.\u001b[K\n","remote: Total 3023 (delta 757), reused 1307 (delta 432), pack-reused 0\u001b[K\n","Receiving objects: 100% (3023/3023), 33.23 MiB | 27.23 MiB/s, done.\n","Resolving deltas: 100% (757/757), done.\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8O9q3CL5z0V-","executionInfo":{"status":"ok","timestamp":1635211788227,"user_tz":-480,"elapsed":38804,"user":{"displayName":"yx IYATT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjkWQveQ9aeFabkZ0xN-od5GWsZF5pnqb-LIQcm=s64","userId":"12018810969794285660"}},"outputId":"ea2f88e4-f1a2-47db-97e2-c05a97bc0fec"},"source":["!cd work-temp/models/research && protoc object_detection/protos/*.proto --python_out=. && cp object_detection/packages/tf2/setup.py . && pip3 install . "],"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Processing /content/work-temp/models/research\n","\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n","   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n","Collecting avro-python3\n","  Downloading avro-python3-1.10.2.tar.gz (38 kB)\n","Collecting apache-beam\n","  Downloading apache_beam-2.33.0-cp37-cp37m-manylinux2010_x86_64.whl (9.8 MB)\n","\u001b[K     |████████████████████████████████| 9.8 MB 6.8 MB/s \n","\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (7.1.2)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (4.2.6)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (3.4.3)\n","Requirement already satisfied: Cython in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.29.24)\n","Requirement already satisfied: contextlib2 in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.5.5)\n","Collecting tf-slim\n","  Downloading tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n","\u001b[K     |████████████████████████████████| 352 kB 40.3 MB/s \n","\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.15.0)\n","Requirement already satisfied: pycocotools in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (2.0.2)\n","Collecting lvis\n","  Downloading lvis-0.5.3-py3-none-any.whl (14 kB)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.4.1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.1.5)\n","Collecting tf-models-official>=2.5.1\n","  Downloading tf_models_official-2.6.0-py2.py3-none-any.whl (1.8 MB)\n","\u001b[K     |████████████████████████████████| 1.8 MB 37.4 MB/s \n","\u001b[?25hRequirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (5.4.8)\n","Requirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.5.12)\n","Collecting py-cpuinfo>=3.3.0\n","  Downloading py-cpuinfo-8.0.0.tar.gz (99 kB)\n","\u001b[K     |████████████████████████████████| 99 kB 9.2 MB/s \n","\u001b[?25hCollecting sentencepiece\n","  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 42.6 MB/s \n","\u001b[?25hCollecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 18.9 MB/s \n","\u001b[?25hRequirement already satisfied: tensorflow>=2.5.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (2.6.0)\n","Collecting seqeval\n","  Downloading seqeval-1.2.2.tar.gz (43 kB)\n","\u001b[K     |████████████████████████████████| 43 kB 2.0 MB/s \n","\u001b[?25hRequirement already satisfied: oauth2client in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.1.3)\n","Collecting sacrebleu\n","  Downloading sacrebleu-2.0.0-py3-none-any.whl (90 kB)\n","\u001b[K     |████████████████████████████████| 90 kB 9.3 MB/s \n","\u001b[?25hRequirement already satisfied: gin-config in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.4.0)\n","Collecting tensorflow-model-optimization>=0.4.1\n","  Downloading tensorflow_model_optimization-0.7.0-py2.py3-none-any.whl (213 kB)\n","\u001b[K     |████████████████████████████████| 213 kB 40.8 MB/s \n","\u001b[?25hCollecting tensorflow-text>=2.5.0\n","  Downloading tensorflow_text-2.6.0-cp37-cp37m-manylinux1_x86_64.whl (4.4 MB)\n","\u001b[K     |████████████████████████████████| 4.4 MB 34.8 MB/s \n","\u001b[?25hCollecting tensorflow-addons\n","  Downloading tensorflow_addons-0.14.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n","\u001b[K     |████████████████████████████████| 1.1 MB 34.6 MB/s \n","\u001b[?25hCollecting opencv-python-headless\n","  Downloading opencv_python_headless-4.5.4.58-cp37-cp37m-manylinux2014_x86_64.whl (47.6 MB)\n","\u001b[K     |████████████████████████████████| 47.6 MB 32 kB/s \n","\u001b[?25hRequirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.12.8)\n","Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.19.5)\n","Requirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.12.0)\n","Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.0.1)\n","Requirement already satisfied: google-api-core<2dev,>=1.21.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.26.3)\n","Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.0.1)\n","Requirement already satisfied: google-auth>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.35.0)\n","Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.0.4)\n","Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.17.4)\n","Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (57.4.0)\n","Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.53.0)\n","Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.23.0)\n","Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2018.9)\n","Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (21.0)\n","Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.18.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.7.2)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.2.8)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.2.4)\n","Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.24.3)\n","Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2.8.2)\n","Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (5.0.2)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2021.5.30)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (4.62.3)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.4.7)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.4.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.0.4)\n","Requirement already satisfied: grpcio<2.0,>=1.37.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (1.41.0)\n","Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (1.1.2)\n","Requirement already satisfied: keras~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (2.6.0)\n","Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.0)\n","Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (0.37.0)\n","Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (0.4.0)\n","Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (0.2.0)\n","Requirement already satisfied: clang~=5.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (5.0)\n","Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (0.12.0)\n","Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (1.6.3)\n","Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (3.7.4.3)\n","Requirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (3.1.0)\n","Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (1.12.1)\n","Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (1.1.0)\n","Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (2.6.0)\n","Requirement already satisfied: tensorflow-estimator~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (2.6.0)\n","Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (1.12)\n","Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (1.5.2)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (0.4.6)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (1.8.0)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (0.6.1)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (1.0.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.4)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (1.3.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (4.8.1)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (3.1.1)\n","Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official>=2.5.1->object-detection==0.1) (0.1.6)\n","Requirement already satisfied: pydot<2,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.3.0)\n","Collecting orjson<4.0\n","  Downloading orjson-3.6.4-cp37-cp37m-manylinux_2_24_x86_64.whl (249 kB)\n","\u001b[K     |████████████████████████████████| 249 kB 34.9 MB/s \n","\u001b[?25hCollecting hdfs<3.0.0,>=2.1.0\n","  Downloading hdfs-2.6.0-py3-none-any.whl (33 kB)\n","Collecting future<1.0.0,>=0.18.2\n","  Downloading future-0.18.2.tar.gz (829 kB)\n","\u001b[K     |████████████████████████████████| 829 kB 7.4 MB/s \n","\u001b[?25hCollecting fastavro<2,>=0.21.4\n","  Downloading fastavro-1.4.6-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n","\u001b[K     |████████████████████████████████| 2.3 MB 23.0 MB/s \n","\u001b[?25hCollecting requests<3.0.0dev,>=2.18.0\n","  Downloading requests-2.26.0-py2.py3-none-any.whl (62 kB)\n","\u001b[K     |████████████████████████████████| 62 kB 824 kB/s \n","\u001b[?25hRequirement already satisfied: crcmod<2.0,>=1.7 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.7)\n","Requirement already satisfied: pyarrow<5.0.0,>=0.15.1 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (3.0.0)\n","Requirement already satisfied: pymongo<4.0.0,>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (3.12.0)\n","Collecting avro-python3\n","  Downloading avro-python3-1.9.2.1.tar.gz (37 kB)\n","Collecting dill<0.3.2,>=0.3.1.1\n","  Downloading dill-0.3.1.1.tar.gz (151 kB)\n","\u001b[K     |████████████████████████████████| 151 kB 20.4 MB/s \n","\u001b[?25hRequirement already satisfied: docopt in /usr/local/lib/python3.7/dist-packages (from hdfs<3.0.0,>=2.1.0->apache-beam->object-detection==0.1) (0.6.2)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.0.6)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard~=2.6->tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (3.6.0)\n","Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (4.5.3.56)\n","Requirement already satisfied: kiwisolver>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (1.3.2)\n","Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (0.10.0)\n","Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.3)\n","Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from sacrebleu->tf-models-official>=2.5.1->object-detection==0.1) (0.8.9)\n","Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from sacrebleu->tf-models-official>=2.5.1->object-detection==0.1) (2019.12.20)\n","Collecting portalocker\n","  Downloading portalocker-2.3.2-py2.py3-none-any.whl (15 kB)\n","Collecting colorama\n","  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n","Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval->tf-models-official>=2.5.1->object-detection==0.1) (0.22.2.post1)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.0.1)\n","Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons->tf-models-official>=2.5.1->object-detection==0.1) (2.7.1)\n","Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (1.2.0)\n","Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (5.2.2)\n","Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (21.2.0)\n","Requirement already satisfied: promise in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (2.3)\n","Building wheels for collected packages: object-detection, py-cpuinfo, avro-python3, dill, future, seqeval\n","  Building wheel for object-detection (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for object-detection: filename=object_detection-0.1-py3-none-any.whl size=1675727 sha256=77de55da64d52d727a3e53724264c22689d5229a36c9e500a41e119280d61d2b\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-xlblarfe/wheels/db/db/48/c643387f9242df2b7e09dc922c7b5b1fefefa1fb81d26df8c7\n","  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for py-cpuinfo: filename=py_cpuinfo-8.0.0-py3-none-any.whl size=22258 sha256=0121a5f270590998f2ec301a8cc557ecc668a52cd7981f00c0d97877ffdbdf00\n","  Stored in directory: /root/.cache/pip/wheels/d2/f1/1f/041add21dc9c4220157f1bd2bd6afe1f1a49524c3396b94401\n","  Building wheel for avro-python3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for avro-python3: filename=avro_python3-1.9.2.1-py3-none-any.whl size=43512 sha256=61e0dce608508f046a207f5b015443ac978abb82a64b63ada7d6c97b6b8ac795\n","  Stored in directory: /root/.cache/pip/wheels/bc/49/5f/fdb5b9d85055c478213e0158ac122b596816149a02d82e0ab1\n","  Building wheel for dill (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78546 sha256=7333e909dc05019064cda020a966a78ee85d7b6de75d4a38e79b97391b14d7f2\n","  Stored in directory: /root/.cache/pip/wheels/a4/61/fd/c57e374e580aa78a45ed78d5859b3a44436af17e22ca53284f\n","  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491070 sha256=441cf0c435abbb9b6d7dbc6815229e2ce6630b0a46c266ac68d35ce40f347f76\n","  Stored in directory: /root/.cache/pip/wheels/56/b0/fe/4410d17b32f1f0c3cf54cdfb2bc04d7b4b8f4ae377e2229ba0\n","  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16181 sha256=1f700f4cb6becaff1f059d1e796bfceaa38d7612130cfbd7dd0211e86e820015\n","  Stored in directory: /root/.cache/pip/wheels/05/96/ee/7cac4e74f3b19e3158dce26a20a1c86b3533c43ec72a549fd7\n","Successfully built object-detection py-cpuinfo avro-python3 dill future seqeval\n","Installing collected packages: requests, portalocker, future, dill, colorama, tf-slim, tensorflow-text, tensorflow-model-optimization, tensorflow-addons, seqeval, sentencepiece, sacrebleu, pyyaml, py-cpuinfo, orjson, opencv-python-headless, hdfs, fastavro, avro-python3, tf-models-official, lvis, apache-beam, object-detection\n","  Attempting uninstall: requests\n","    Found existing installation: requests 2.23.0\n","    Uninstalling requests-2.23.0:\n","      Successfully uninstalled requests-2.23.0\n","  Attempting uninstall: future\n","    Found existing installation: future 0.16.0\n","    Uninstalling future-0.16.0:\n","      Successfully uninstalled future-0.16.0\n","  Attempting uninstall: dill\n","    Found existing installation: dill 0.3.4\n","    Uninstalling dill-0.3.4:\n","      Successfully uninstalled dill-0.3.4\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","multiprocess 0.70.12.2 requires dill>=0.3.4, but you have dill 0.3.1.1 which is incompatible.\n","google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.26.0 which is incompatible.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n","Successfully installed apache-beam-2.33.0 avro-python3-1.9.2.1 colorama-0.4.4 dill-0.3.1.1 fastavro-1.4.6 future-0.18.2 hdfs-2.6.0 lvis-0.5.3 object-detection-0.1 opencv-python-headless-4.5.4.58 orjson-3.6.4 portalocker-2.3.2 py-cpuinfo-8.0.0 pyyaml-6.0 requests-2.26.0 sacrebleu-2.0.0 sentencepiece-0.1.96 seqeval-1.2.2 tensorflow-addons-0.14.0 tensorflow-model-optimization-0.7.0 tensorflow-text-2.6.0 tf-models-official-2.6.0 tf-slim-1.1.0\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iwZvegYG02yY","executionInfo":{"status":"ok","timestamp":1635211789255,"user_tz":-480,"elapsed":1058,"user":{"displayName":"yx IYATT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjkWQveQ9aeFabkZ0xN-od5GWsZF5pnqb-LIQcm=s64","userId":"12018810969794285660"}},"outputId":"728f9485-0edb-415a-efd8-9eab424b58ca"},"source":["# 下载预训练模型\n","!wget {PRETRAINED_MODEL_URL}\n","!mv {PRETRAINED_MODEL_NAME+'.tar.gz'} {paths['PRETRAINED_MODEL_PATH']}\n","!cd {paths['PRETRAINED_MODEL_PATH']} && tar -zxvf {PRETRAINED_MODEL_NAME+'.tar.gz'}"],"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["--2021-10-26 01:29:47--  http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz\n","Resolving download.tensorflow.org (download.tensorflow.org)... 209.85.146.128, 2607:f8b0:4001:c1f::80\n","Connecting to download.tensorflow.org (download.tensorflow.org)|209.85.146.128|:80... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 20515344 (20M) [application/x-tar]\n","Saving to: ‘ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz’\n","\n","ssd_mobilenet_v2_fp 100%[===================>]  19.56M   117MB/s    in 0.2s    \n","\n","2021-10-26 01:29:48 (117 MB/s) - ‘ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz’ saved [20515344/20515344]\n","\n","ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/\n","ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/\n","ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/ckpt-0.data-00000-of-00001\n","ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/checkpoint\n","ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/ckpt-0.index\n","ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/pipeline.config\n","ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/\n","ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/saved_model.pb\n","ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/variables/\n","ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/variables/variables.data-00000-of-00001\n","ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/variables/variables.index\n"]}]},{"cell_type":"markdown","metadata":{"id":"ZCnKvzEc1EbV"},"source":["## 创建标签图文件"]},{"cell_type":"code","metadata":{"id":"YEQwPvuq1C_y","executionInfo":{"status":"ok","timestamp":1635211789256,"user_tz":-480,"elapsed":22,"user":{"displayName":"yx IYATT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjkWQveQ9aeFabkZ0xN-od5GWsZF5pnqb-LIQcm=s64","userId":"12018810969794285660"}}},"source":["labels = [{'name':'cone-bucket', 'id':1}]\n","\n","with open(files['LABELMAP'], 'w') as f:\n","    for label in labels:\n","        f.write('item { \\n')\n","        f.write('\\tname:\\'{}\\'\\n'.format(label['name']))\n","        f.write('\\tid:{}\\n'.format(label['id']))\n","        f.write('}\\n')"],"execution_count":11,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YGWKgbzq1Q_v"},"source":["## 转换数据"]},{"cell_type":"code","metadata":{"id":"zsYKuejG1YnA","executionInfo":{"status":"ok","timestamp":1635211789257,"user_tz":-480,"elapsed":20,"user":{"displayName":"yx IYATT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjkWQveQ9aeFabkZ0xN-od5GWsZF5pnqb-LIQcm=s64","userId":"12018810969794285660"}}},"source":["# OPTIONAL IF RUNNING ON COLAB\n","ARCHIVE_FILES = os.path.join(paths['IMAGE_PATH'], 'archive.tar.gz')\n","if os.path.exists(ARCHIVE_FILES):\n","  !tar -zxvf {ARCHIVE_FILES}"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"yZrXPoT-1b-Q","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1635211789257,"user_tz":-480,"elapsed":18,"user":{"displayName":"yx IYATT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjkWQveQ9aeFabkZ0xN-od5GWsZF5pnqb-LIQcm=s64","userId":"12018810969794285660"}},"outputId":"a8ca4e91-c1b0-422a-b777-7a2ab4dca795"},"source":["!tar xvf cone-bucket.tar.gz"],"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["cone-bucket/\n","cone-bucket/train/\n","cone-bucket/train/17.jpeg\n","cone-bucket/train/11.jpeg\n","cone-bucket/train/21.xml\n","cone-bucket/train/4.xml\n","cone-bucket/train/34.xml\n","cone-bucket/train/21.jpeg\n","cone-bucket/train/5.jpeg\n","cone-bucket/train/36.jpeg\n","cone-bucket/train/22.xml\n","cone-bucket/train/35.xml\n","cone-bucket/train/7.jpeg\n","cone-bucket/train/25.xml\n","cone-bucket/train/13.jpeg\n","cone-bucket/train/7.xml\n","cone-bucket/train/23.xml\n","cone-bucket/train/19.xml\n","cone-bucket/train/33.xml\n","cone-bucket/train/26.xml\n","cone-bucket/train/4.jpeg\n","cone-bucket/train/32.xml\n","cone-bucket/train/14.jpeg\n","cone-bucket/train/2.jpeg\n","cone-bucket/train/30.jpeg\n","cone-bucket/train/8.jpeg\n","cone-bucket/train/20.xml\n","cone-bucket/train/12.xml\n","cone-bucket/train/15.jpeg\n","cone-bucket/train/22.jpeg\n","cone-bucket/train/24.jpeg\n","cone-bucket/train/9.xml\n","cone-bucket/train/28.xml\n","cone-bucket/train/31.jpeg\n","cone-bucket/train/16.jpeg\n","cone-bucket/train/14.xml\n","cone-bucket/train/13.xml\n","cone-bucket/train/2.xml\n","cone-bucket/train/27.jpeg\n","cone-bucket/train/10.jpeg\n","cone-bucket/train/10.xml\n","cone-bucket/train/17.xml\n","cone-bucket/train/15.xml\n","cone-bucket/train/24.xml\n","cone-bucket/train/25.jpeg\n","cone-bucket/train/26.jpeg\n","cone-bucket/train/1.jpeg\n","cone-bucket/train/3.jpeg\n","cone-bucket/train/19.jpeg\n","cone-bucket/train/8.xml\n","cone-bucket/train/11.xml\n","cone-bucket/train/34.jpeg\n","cone-bucket/train/23.jpeg\n","cone-bucket/train/36.xml\n","cone-bucket/train/32.jpeg\n","cone-bucket/train/18.xml\n","cone-bucket/train/9.jpeg\n","cone-bucket/train/12.jpeg\n","cone-bucket/train/29.jpeg\n","cone-bucket/train/20.jpeg\n","cone-bucket/train/31.xml\n","cone-bucket/train/33.jpeg\n","cone-bucket/train/3.xml\n","cone-bucket/train/1.xml\n","cone-bucket/train/29.xml\n","cone-bucket/train/6.jpeg\n","cone-bucket/train/30.xml\n","cone-bucket/train/5.xml\n","cone-bucket/train/27.xml\n","cone-bucket/train/16.xml\n","cone-bucket/train/35.jpeg\n","cone-bucket/train/18.jpeg\n","cone-bucket/train/28.jpeg\n","cone-bucket/train/6.xml\n","cone-bucket/test/\n","cone-bucket/test/4.xml\n","cone-bucket/test/5.jpeg\n","cone-bucket/test/7.jpeg\n","cone-bucket/test/7.xml\n","cone-bucket/test/4.jpeg\n","cone-bucket/test/2.jpeg\n","cone-bucket/test/2.xml\n","cone-bucket/test/1.jpeg\n","cone-bucket/test/3.jpeg\n","cone-bucket/test/3.xml\n","cone-bucket/test/1.xml\n","cone-bucket/test/6.jpeg\n","cone-bucket/test/5.xml\n","cone-bucket/test/6.xml\n"]}]},{"cell_type":"code","metadata":{"id":"ZsckLBwHaa_g","executionInfo":{"status":"ok","timestamp":1635211789791,"user_tz":-480,"elapsed":541,"user":{"displayName":"yx IYATT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjkWQveQ9aeFabkZ0xN-od5GWsZF5pnqb-LIQcm=s64","userId":"12018810969794285660"}}},"source":["!cp generate_tfrecord.py {paths['SCRIPTS_PATH']}\n","!cp -r cone-bucket/* {paths['IMAGE_PATH']}"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8u2GZP4jauB5","executionInfo":{"status":"ok","timestamp":1635211796007,"user_tz":-480,"elapsed":6224,"user":{"displayName":"yx IYATT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjkWQveQ9aeFabkZ0xN-od5GWsZF5pnqb-LIQcm=s64","userId":"12018810969794285660"}},"outputId":"6e937288-7ef4-47b1-86b6-c3faab74814d"},"source":["!python3 {files['TF_RECORD_SCRIPT']} -x {paths['IMAGE_PATH'] + '/train/'} -l {files['LABELMAP']} -o {paths['ANNOTATION_PATH'] + '/train.record'} \n","!python3 {files['TF_RECORD_SCRIPT']} -x {paths['IMAGE_PATH'] + '/test/'} -l {files['LABELMAP']} -o {paths['ANNOTATION_PATH'] + '/test.record'}"],"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Successfully created the TFRecord file: work-temp/workspace/annotations/train.record\n","Successfully created the TFRecord file: work-temp/workspace/annotations/test.record\n"]}]},{"cell_type":"markdown","metadata":{"id":"JMNmTrCIc7eF"},"source":["## 复制模型配置到训练文件夹"]},{"cell_type":"code","metadata":{"id":"NWy2mmVHazPA","executionInfo":{"status":"ok","timestamp":1635211796522,"user_tz":-480,"elapsed":551,"user":{"displayName":"yx IYATT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjkWQveQ9aeFabkZ0xN-od5GWsZF5pnqb-LIQcm=s64","userId":"12018810969794285660"}}},"source":["!cp {paths['PRETRAINED_MODEL_PATH'] + '/' + PRETRAINED_MODEL_NAME + '/pipeline.config'} {paths['CHECKPOINT_PATH']}"],"execution_count":16,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xt-VxOEIhi8Z"},"source":["## 迁移学习配置"]},{"cell_type":"code","metadata":{"id":"ogUT6BxJdDx3","executionInfo":{"status":"ok","timestamp":1635211798232,"user_tz":-480,"elapsed":1716,"user":{"displayName":"yx IYATT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjkWQveQ9aeFabkZ0xN-od5GWsZF5pnqb-LIQcm=s64","userId":"12018810969794285660"}}},"source":["import tensorflow as tf\n","from object_detection.utils import config_util\n","from object_detection.protos import pipeline_pb2\n","from google.protobuf import text_format"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ea3OCrcOhxBn","executionInfo":{"status":"ok","timestamp":1635211798233,"user_tz":-480,"elapsed":25,"user":{"displayName":"yx IYATT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjkWQveQ9aeFabkZ0xN-od5GWsZF5pnqb-LIQcm=s64","userId":"12018810969794285660"}}},"source":["pipeline_config = pipeline_pb2.TrainEvalPipelineConfig()\n","with tf.io.gfile.GFile(files['PIPELINE_CONFIG'], \"r\") as f:                                                                                                                                                                                                                     \n","    proto_str = f.read()                                                                                                                                                                                                                                          \n","    text_format.Merge(proto_str, pipeline_config)"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"CR-lTzixh1Fq","executionInfo":{"status":"ok","timestamp":1635211798234,"user_tz":-480,"elapsed":24,"user":{"displayName":"yx IYATT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjkWQveQ9aeFabkZ0xN-od5GWsZF5pnqb-LIQcm=s64","userId":"12018810969794285660"}}},"source":["pipeline_config.model.ssd.num_classes = len(labels)\n","pipeline_config.train_config.batch_size = 4\n","pipeline_config.train_config.fine_tune_checkpoint = paths['PRETRAINED_MODEL_PATH'] + '/' + PRETRAINED_MODEL_NAME + '/checkpoint/ckpt-0'\n","pipeline_config.train_config.fine_tune_checkpoint_type = 'detection'\n","pipeline_config.train_input_reader.label_map_path= files['LABELMAP']\n","pipeline_config.train_input_reader.tf_record_input_reader.input_path[:] = [paths['ANNOTATION_PATH'] + '/train.record']\n","pipeline_config.eval_input_reader[0].label_map_path = files['LABELMAP']\n","pipeline_config.eval_input_reader[0].tf_record_input_reader.input_path[:] = [paths['ANNOTATION_PATH'] + '/test.record']"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"QsbszbGPh7iV","executionInfo":{"status":"ok","timestamp":1635211798235,"user_tz":-480,"elapsed":23,"user":{"displayName":"yx IYATT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjkWQveQ9aeFabkZ0xN-od5GWsZF5pnqb-LIQcm=s64","userId":"12018810969794285660"}}},"source":["config_text = text_format.MessageToString(pipeline_config)                                                                                                                                                                                                        \n","with tf.io.gfile.GFile(files['PIPELINE_CONFIG'], \"wb\") as f:                                                                                                                                                                                                                     \n","    f.write(config_text)"],"execution_count":20,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ijbUgZDjh9LN"},"source":["## 训练模型"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9flo8O4ph-qc","executionInfo":{"status":"ok","timestamp":1635212301081,"user_tz":-480,"elapsed":502868,"user":{"displayName":"yx IYATT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjkWQveQ9aeFabkZ0xN-od5GWsZF5pnqb-LIQcm=s64","userId":"12018810969794285660"}},"outputId":"a37ff81a-7092-42c6-a3de-715a08f240b2"},"source":["TRAINING_SCRIPT = paths['APIMODEL_PATH'] + '/research/object_detection/model_main_tf2.py'\n","cmd = \"python3 {} --model_dir={} --pipeline_config_path={} --num_train_steps=2000\".format(TRAINING_SCRIPT, paths['CHECKPOINT_PATH'],files['PIPELINE_CONFIG'])\n","print(cmd)\n","!{cmd}"],"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["python3 work-temp/models/research/object_detection/model_main_tf2.py --model_dir=work-temp/workspace/models --pipeline_config_path=work-temp/workspace/models/pipeline.config --num_train_steps=2000\n","2021-10-26 01:30:01.815352: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-10-26 01:30:01.846616: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-10-26 01:30:01.847482: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-10-26 01:30:01.849376: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-10-26 01:30:01.850189: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-10-26 01:30:01.850960: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-10-26 01:30:06.968264: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-10-26 01:30:06.969148: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-10-26 01:30:06.969888: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-10-26 01:30:06.970682: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2021-10-26 01:30:06.970787: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10819 MB memory:  -> device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7\n","INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n","I1026 01:30:07.057699 140671873177472 mirrored_strategy.py:369] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n","INFO:tensorflow:Maybe overwriting train_steps: 2000\n","I1026 01:30:07.062756 140671873177472 config_util.py:552] Maybe overwriting train_steps: 2000\n","INFO:tensorflow:Maybe overwriting use_bfloat16: False\n","I1026 01:30:07.062926 140671873177472 config_util.py:552] Maybe overwriting use_bfloat16: False\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/model_lib_v2.py:558: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","rename to distribute_datasets_from_function\n","W1026 01:30:07.208277 140671873177472 deprecation.py:345] From /usr/local/lib/python3.7/dist-packages/object_detection/model_lib_v2.py:558: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","rename to distribute_datasets_from_function\n","INFO:tensorflow:Reading unweighted datasets: ['work-temp/workspace/annotations/train.record']\n","I1026 01:30:07.220946 140671873177472 dataset_builder.py:163] Reading unweighted datasets: ['work-temp/workspace/annotations/train.record']\n","INFO:tensorflow:Reading record datasets for input file: ['work-temp/workspace/annotations/train.record']\n","I1026 01:30:07.221206 140671873177472 dataset_builder.py:80] Reading record datasets for input file: ['work-temp/workspace/annotations/train.record']\n","INFO:tensorflow:Number of filenames to read: 1\n","I1026 01:30:07.221354 140671873177472 dataset_builder.py:81] Number of filenames to read: 1\n","WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n","W1026 01:30:07.221519 140671873177472 dataset_builder.py:88] num_readers has been reduced to 1 to match input file shards.\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:105: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_deterministic`.\n","W1026 01:30:07.234479 140671873177472 deprecation.py:345] From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:105: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_deterministic`.\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:237: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.map()\n","W1026 01:30:07.269892 140671873177472 deprecation.py:345] From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:237: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.map()\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n","W1026 01:30:15.762816 140671873177472 deprecation.py:345] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n","W1026 01:30:19.351824 140671873177472 deprecation.py:345] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:464: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","W1026 01:30:21.271318 140671873177472 deprecation.py:345] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:464: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","2021-10-26 01:30:24.014130: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n","/usr/local/lib/python3.7/dist-packages/keras/backend.py:401: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n","  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n","2021-10-26 01:30:48.575350: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I1026 01:31:16.745821 140671873177472 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I1026 01:31:16.747232 140671873177472 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I1026 01:31:16.750018 140671873177472 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I1026 01:31:16.751079 140671873177472 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I1026 01:31:16.753880 140671873177472 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I1026 01:31:16.754945 140671873177472 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I1026 01:31:16.757609 140671873177472 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I1026 01:31:16.758775 140671873177472 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I1026 01:31:16.761558 140671873177472 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I1026 01:31:16.762611 140671873177472 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py:617: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use fn_output_signature instead\n","W1026 01:31:17.677470 140667660023552 deprecation.py:548] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py:617: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use fn_output_signature instead\n","INFO:tensorflow:Step 100 per-step time 0.579s\n","I1026 01:32:14.973588 140671873177472 model_lib_v2.py:700] Step 100 per-step time 0.579s\n","INFO:tensorflow:{'Loss/classification_loss': 0.22041924,\n"," 'Loss/localization_loss': 0.20118015,\n"," 'Loss/regularization_loss': 0.15392677,\n"," 'Loss/total_loss': 0.5755262,\n"," 'learning_rate': 0.0319994}\n","I1026 01:32:14.974021 140671873177472 model_lib_v2.py:701] {'Loss/classification_loss': 0.22041924,\n"," 'Loss/localization_loss': 0.20118015,\n"," 'Loss/regularization_loss': 0.15392677,\n"," 'Loss/total_loss': 0.5755262,\n"," 'learning_rate': 0.0319994}\n","INFO:tensorflow:Step 200 per-step time 0.191s\n","I1026 01:32:34.069109 140671873177472 model_lib_v2.py:700] Step 200 per-step time 0.191s\n","INFO:tensorflow:{'Loss/classification_loss': 0.186354,\n"," 'Loss/localization_loss': 0.24607137,\n"," 'Loss/regularization_loss': 0.15379459,\n"," 'Loss/total_loss': 0.58621997,\n"," 'learning_rate': 0.0373328}\n","I1026 01:32:34.069485 140671873177472 model_lib_v2.py:701] {'Loss/classification_loss': 0.186354,\n"," 'Loss/localization_loss': 0.24607137,\n"," 'Loss/regularization_loss': 0.15379459,\n"," 'Loss/total_loss': 0.58621997,\n"," 'learning_rate': 0.0373328}\n","INFO:tensorflow:Step 300 per-step time 0.191s\n","I1026 01:32:53.146590 140671873177472 model_lib_v2.py:700] Step 300 per-step time 0.191s\n","INFO:tensorflow:{'Loss/classification_loss': 0.1964686,\n"," 'Loss/localization_loss': 0.19684294,\n"," 'Loss/regularization_loss': 0.15356308,\n"," 'Loss/total_loss': 0.54687464,\n"," 'learning_rate': 0.0426662}\n","I1026 01:32:53.146983 140671873177472 model_lib_v2.py:701] {'Loss/classification_loss': 0.1964686,\n"," 'Loss/localization_loss': 0.19684294,\n"," 'Loss/regularization_loss': 0.15356308,\n"," 'Loss/total_loss': 0.54687464,\n"," 'learning_rate': 0.0426662}\n","INFO:tensorflow:Step 400 per-step time 0.191s\n","I1026 01:33:12.239807 140671873177472 model_lib_v2.py:700] Step 400 per-step time 0.191s\n","INFO:tensorflow:{'Loss/classification_loss': 0.082740575,\n"," 'Loss/localization_loss': 0.053753812,\n"," 'Loss/regularization_loss': 0.15323135,\n"," 'Loss/total_loss': 0.28972572,\n"," 'learning_rate': 0.047999598}\n","I1026 01:33:12.240153 140671873177472 model_lib_v2.py:701] {'Loss/classification_loss': 0.082740575,\n"," 'Loss/localization_loss': 0.053753812,\n"," 'Loss/regularization_loss': 0.15323135,\n"," 'Loss/total_loss': 0.28972572,\n"," 'learning_rate': 0.047999598}\n","INFO:tensorflow:Step 500 per-step time 0.190s\n","I1026 01:33:31.277105 140671873177472 model_lib_v2.py:700] Step 500 per-step time 0.190s\n","INFO:tensorflow:{'Loss/classification_loss': 0.090925984,\n"," 'Loss/localization_loss': 0.04562963,\n"," 'Loss/regularization_loss': 0.15281408,\n"," 'Loss/total_loss': 0.2893697,\n"," 'learning_rate': 0.053333}\n","I1026 01:33:31.277488 140671873177472 model_lib_v2.py:701] {'Loss/classification_loss': 0.090925984,\n"," 'Loss/localization_loss': 0.04562963,\n"," 'Loss/regularization_loss': 0.15281408,\n"," 'Loss/total_loss': 0.2893697,\n"," 'learning_rate': 0.053333}\n","INFO:tensorflow:Step 600 per-step time 0.192s\n","I1026 01:33:50.484482 140671873177472 model_lib_v2.py:700] Step 600 per-step time 0.192s\n","INFO:tensorflow:{'Loss/classification_loss': 0.070393175,\n"," 'Loss/localization_loss': 0.028677003,\n"," 'Loss/regularization_loss': 0.15235208,\n"," 'Loss/total_loss': 0.25142226,\n"," 'learning_rate': 0.0586664}\n","I1026 01:33:50.484909 140671873177472 model_lib_v2.py:701] {'Loss/classification_loss': 0.070393175,\n"," 'Loss/localization_loss': 0.028677003,\n"," 'Loss/regularization_loss': 0.15235208,\n"," 'Loss/total_loss': 0.25142226,\n"," 'learning_rate': 0.0586664}\n","INFO:tensorflow:Step 700 per-step time 0.190s\n","I1026 01:34:09.494732 140671873177472 model_lib_v2.py:700] Step 700 per-step time 0.190s\n","INFO:tensorflow:{'Loss/classification_loss': 0.067013904,\n"," 'Loss/localization_loss': 0.04381625,\n"," 'Loss/regularization_loss': 0.15187258,\n"," 'Loss/total_loss': 0.26270273,\n"," 'learning_rate': 0.0639998}\n","I1026 01:34:09.495144 140671873177472 model_lib_v2.py:701] {'Loss/classification_loss': 0.067013904,\n"," 'Loss/localization_loss': 0.04381625,\n"," 'Loss/regularization_loss': 0.15187258,\n"," 'Loss/total_loss': 0.26270273,\n"," 'learning_rate': 0.0639998}\n","INFO:tensorflow:Step 800 per-step time 0.191s\n","I1026 01:34:28.591468 140671873177472 model_lib_v2.py:700] Step 800 per-step time 0.191s\n","INFO:tensorflow:{'Loss/classification_loss': 0.056679238,\n"," 'Loss/localization_loss': 0.031261027,\n"," 'Loss/regularization_loss': 0.15131046,\n"," 'Loss/total_loss': 0.23925072,\n"," 'learning_rate': 0.069333196}\n","I1026 01:34:28.591833 140671873177472 model_lib_v2.py:701] {'Loss/classification_loss': 0.056679238,\n"," 'Loss/localization_loss': 0.031261027,\n"," 'Loss/regularization_loss': 0.15131046,\n"," 'Loss/total_loss': 0.23925072,\n"," 'learning_rate': 0.069333196}\n","INFO:tensorflow:Step 900 per-step time 0.190s\n","I1026 01:34:47.546597 140671873177472 model_lib_v2.py:700] Step 900 per-step time 0.190s\n","INFO:tensorflow:{'Loss/classification_loss': 0.042810142,\n"," 'Loss/localization_loss': 0.027852125,\n"," 'Loss/regularization_loss': 0.15068397,\n"," 'Loss/total_loss': 0.22134623,\n"," 'learning_rate': 0.074666604}\n","I1026 01:34:47.546973 140671873177472 model_lib_v2.py:701] {'Loss/classification_loss': 0.042810142,\n"," 'Loss/localization_loss': 0.027852125,\n"," 'Loss/regularization_loss': 0.15068397,\n"," 'Loss/total_loss': 0.22134623,\n"," 'learning_rate': 0.074666604}\n","INFO:tensorflow:Step 1000 per-step time 0.191s\n","I1026 01:35:06.609231 140671873177472 model_lib_v2.py:700] Step 1000 per-step time 0.191s\n","INFO:tensorflow:{'Loss/classification_loss': 0.11242008,\n"," 'Loss/localization_loss': 0.03387857,\n"," 'Loss/regularization_loss': 0.15009658,\n"," 'Loss/total_loss': 0.29639524,\n"," 'learning_rate': 0.08}\n","I1026 01:35:06.609584 140671873177472 model_lib_v2.py:701] {'Loss/classification_loss': 0.11242008,\n"," 'Loss/localization_loss': 0.03387857,\n"," 'Loss/regularization_loss': 0.15009658,\n"," 'Loss/total_loss': 0.29639524,\n"," 'learning_rate': 0.08}\n","INFO:tensorflow:Step 1100 per-step time 0.197s\n","I1026 01:35:26.266614 140671873177472 model_lib_v2.py:700] Step 1100 per-step time 0.197s\n","INFO:tensorflow:{'Loss/classification_loss': 0.11769024,\n"," 'Loss/localization_loss': 0.03635134,\n"," 'Loss/regularization_loss': 0.14956312,\n"," 'Loss/total_loss': 0.30360472,\n"," 'learning_rate': 0.07999918}\n","I1026 01:35:26.267153 140671873177472 model_lib_v2.py:701] {'Loss/classification_loss': 0.11769024,\n"," 'Loss/localization_loss': 0.03635134,\n"," 'Loss/regularization_loss': 0.14956312,\n"," 'Loss/total_loss': 0.30360472,\n"," 'learning_rate': 0.07999918}\n","INFO:tensorflow:Step 1200 per-step time 0.191s\n","I1026 01:35:45.320980 140671873177472 model_lib_v2.py:700] Step 1200 per-step time 0.191s\n","INFO:tensorflow:{'Loss/classification_loss': 0.07593348,\n"," 'Loss/localization_loss': 0.029460631,\n"," 'Loss/regularization_loss': 0.14916274,\n"," 'Loss/total_loss': 0.25455683,\n"," 'learning_rate': 0.079996705}\n","I1026 01:35:45.321355 140671873177472 model_lib_v2.py:701] {'Loss/classification_loss': 0.07593348,\n"," 'Loss/localization_loss': 0.029460631,\n"," 'Loss/regularization_loss': 0.14916274,\n"," 'Loss/total_loss': 0.25455683,\n"," 'learning_rate': 0.079996705}\n","INFO:tensorflow:Step 1300 per-step time 0.189s\n","I1026 01:36:04.267268 140671873177472 model_lib_v2.py:700] Step 1300 per-step time 0.189s\n","INFO:tensorflow:{'Loss/classification_loss': 0.046333533,\n"," 'Loss/localization_loss': 0.015628256,\n"," 'Loss/regularization_loss': 0.14839719,\n"," 'Loss/total_loss': 0.21035898,\n"," 'learning_rate': 0.0799926}\n","I1026 01:36:04.267645 140671873177472 model_lib_v2.py:701] {'Loss/classification_loss': 0.046333533,\n"," 'Loss/localization_loss': 0.015628256,\n"," 'Loss/regularization_loss': 0.14839719,\n"," 'Loss/total_loss': 0.21035898,\n"," 'learning_rate': 0.0799926}\n","INFO:tensorflow:Step 1400 per-step time 0.192s\n","I1026 01:36:23.475268 140671873177472 model_lib_v2.py:700] Step 1400 per-step time 0.192s\n","INFO:tensorflow:{'Loss/classification_loss': 0.065168284,\n"," 'Loss/localization_loss': 0.028980982,\n"," 'Loss/regularization_loss': 0.14764695,\n"," 'Loss/total_loss': 0.24179621,\n"," 'learning_rate': 0.07998685}\n","I1026 01:36:23.475631 140671873177472 model_lib_v2.py:701] {'Loss/classification_loss': 0.065168284,\n"," 'Loss/localization_loss': 0.028980982,\n"," 'Loss/regularization_loss': 0.14764695,\n"," 'Loss/total_loss': 0.24179621,\n"," 'learning_rate': 0.07998685}\n","INFO:tensorflow:Step 1500 per-step time 0.190s\n","I1026 01:36:42.476115 140671873177472 model_lib_v2.py:700] Step 1500 per-step time 0.190s\n","INFO:tensorflow:{'Loss/classification_loss': 0.06672656,\n"," 'Loss/localization_loss': 0.045010496,\n"," 'Loss/regularization_loss': 0.14691561,\n"," 'Loss/total_loss': 0.2586527,\n"," 'learning_rate': 0.07997945}\n","I1026 01:36:42.476491 140671873177472 model_lib_v2.py:701] {'Loss/classification_loss': 0.06672656,\n"," 'Loss/localization_loss': 0.045010496,\n"," 'Loss/regularization_loss': 0.14691561,\n"," 'Loss/total_loss': 0.2586527,\n"," 'learning_rate': 0.07997945}\n","INFO:tensorflow:Step 1600 per-step time 0.190s\n","I1026 01:37:01.494705 140671873177472 model_lib_v2.py:700] Step 1600 per-step time 0.190s\n","INFO:tensorflow:{'Loss/classification_loss': 0.076098226,\n"," 'Loss/localization_loss': 0.012826317,\n"," 'Loss/regularization_loss': 0.14617828,\n"," 'Loss/total_loss': 0.23510282,\n"," 'learning_rate': 0.079970405}\n","I1026 01:37:01.495116 140671873177472 model_lib_v2.py:701] {'Loss/classification_loss': 0.076098226,\n"," 'Loss/localization_loss': 0.012826317,\n"," 'Loss/regularization_loss': 0.14617828,\n"," 'Loss/total_loss': 0.23510282,\n"," 'learning_rate': 0.079970405}\n","INFO:tensorflow:Step 1700 per-step time 0.190s\n","I1026 01:37:20.515368 140671873177472 model_lib_v2.py:700] Step 1700 per-step time 0.190s\n","INFO:tensorflow:{'Loss/classification_loss': 0.055390097,\n"," 'Loss/localization_loss': 0.019488197,\n"," 'Loss/regularization_loss': 0.14541794,\n"," 'Loss/total_loss': 0.22029623,\n"," 'learning_rate': 0.07995972}\n","I1026 01:37:20.515777 140671873177472 model_lib_v2.py:701] {'Loss/classification_loss': 0.055390097,\n"," 'Loss/localization_loss': 0.019488197,\n"," 'Loss/regularization_loss': 0.14541794,\n"," 'Loss/total_loss': 0.22029623,\n"," 'learning_rate': 0.07995972}\n","INFO:tensorflow:Step 1800 per-step time 0.190s\n","I1026 01:37:39.528975 140671873177472 model_lib_v2.py:700] Step 1800 per-step time 0.190s\n","INFO:tensorflow:{'Loss/classification_loss': 0.04607328,\n"," 'Loss/localization_loss': 0.025557715,\n"," 'Loss/regularization_loss': 0.14466003,\n"," 'Loss/total_loss': 0.21629103,\n"," 'learning_rate': 0.0799474}\n","I1026 01:37:39.529317 140671873177472 model_lib_v2.py:701] {'Loss/classification_loss': 0.04607328,\n"," 'Loss/localization_loss': 0.025557715,\n"," 'Loss/regularization_loss': 0.14466003,\n"," 'Loss/total_loss': 0.21629103,\n"," 'learning_rate': 0.0799474}\n","INFO:tensorflow:Step 1900 per-step time 0.191s\n","I1026 01:37:58.624984 140671873177472 model_lib_v2.py:700] Step 1900 per-step time 0.191s\n","INFO:tensorflow:{'Loss/classification_loss': 0.043355104,\n"," 'Loss/localization_loss': 0.016344482,\n"," 'Loss/regularization_loss': 0.14387198,\n"," 'Loss/total_loss': 0.20357156,\n"," 'learning_rate': 0.07993342}\n","I1026 01:37:58.625344 140671873177472 model_lib_v2.py:701] {'Loss/classification_loss': 0.043355104,\n"," 'Loss/localization_loss': 0.016344482,\n"," 'Loss/regularization_loss': 0.14387198,\n"," 'Loss/total_loss': 0.20357156,\n"," 'learning_rate': 0.07993342}\n","INFO:tensorflow:Step 2000 per-step time 0.190s\n","I1026 01:38:17.593592 140671873177472 model_lib_v2.py:700] Step 2000 per-step time 0.190s\n","INFO:tensorflow:{'Loss/classification_loss': 0.056405984,\n"," 'Loss/localization_loss': 0.021888386,\n"," 'Loss/regularization_loss': 0.14311635,\n"," 'Loss/total_loss': 0.22141072,\n"," 'learning_rate': 0.07991781}\n","I1026 01:38:17.594014 140671873177472 model_lib_v2.py:701] {'Loss/classification_loss': 0.056405984,\n"," 'Loss/localization_loss': 0.021888386,\n"," 'Loss/regularization_loss': 0.14311635,\n"," 'Loss/total_loss': 0.22141072,\n"," 'learning_rate': 0.07991781}\n"]}]},{"cell_type":"markdown","metadata":{"id":"bDe5IZ30i3je"},"source":["## 载入训练模型"]},{"cell_type":"code","metadata":{"id":"20wqLVLpi6pg","executionInfo":{"status":"ok","timestamp":1635212301627,"user_tz":-480,"elapsed":585,"user":{"displayName":"yx IYATT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjkWQveQ9aeFabkZ0xN-od5GWsZF5pnqb-LIQcm=s64","userId":"12018810969794285660"}}},"source":["import tensorflow as tf\n","from object_detection.utils import label_map_util\n","from object_detection.utils import visualization_utils as viz_utils\n","from object_detection.builders import model_builder\n","from object_detection.utils import config_util"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"M5Zbtinfi98C","executionInfo":{"status":"ok","timestamp":1635212375138,"user_tz":-480,"elapsed":378,"user":{"displayName":"yx IYATT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjkWQveQ9aeFabkZ0xN-od5GWsZF5pnqb-LIQcm=s64","userId":"12018810969794285660"}}},"source":["# 载入 pipeline config 和构建一个检测模型\n","configs = config_util.get_configs_from_pipeline_file(files['PIPELINE_CONFIG'])\n","detection_model = model_builder.build(model_config=configs['model'], is_training=False)\n","\n","ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n","ckpt.restore(os.path.join(paths['CHECKPOINT_PATH'], 'ckpt-3')).expect_partial()\n","\n","@tf.function\n","def detect_fn(image):\n","    image, shapes = detection_model.preprocess(image)\n","    prediction_dict = detection_model.predict(image, shapes)\n","    detections = detection_model.postprocess(prediction_dict, shapes)\n","    return detections"],"execution_count":24,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"82M2g4KxjCeO"},"source":["# 测试检测效果"]},{"cell_type":"code","metadata":{"id":"agih1yrLjAIC","executionInfo":{"status":"ok","timestamp":1635212380300,"user_tz":-480,"elapsed":367,"user":{"displayName":"yx IYATT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjkWQveQ9aeFabkZ0xN-od5GWsZF5pnqb-LIQcm=s64","userId":"12018810969794285660"}}},"source":["import cv2 \n","import numpy as np"],"execution_count":25,"outputs":[]},{"cell_type":"code","metadata":{"id":"c3qNDvS5jI53","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1635212439621,"user_tz":-480,"elapsed":47815,"user":{"displayName":"yx IYATT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjkWQveQ9aeFabkZ0xN-od5GWsZF5pnqb-LIQcm=s64","userId":"12018810969794285660"}},"outputId":"77affb66-4ccb-4490-dc2e-aadc0213229d"},"source":["category_index = label_map_util.create_category_index_from_labelmap(files['LABELMAP'])\n"," \n","for i in range(1, 8):\n","    img = cv2.imread(paths['IMAGE_PATH'] + '/test/' + str(i) + '.jpeg')\n","    image_np = np.array(img)\n","\n","    input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n","    detections = detect_fn(input_tensor)\n","\n","    num_detections = int(detections.pop('num_detections'))\n","    detections = {key: value[0, :num_detections].numpy() for key, value in detections.items()}\n","    detections['num_detections'] = num_detections\n","\n","    detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n","\n","    label_id_offset = 1\n","    image_np_with_detections = image_np.copy()\n","\n","    viz_utils.visualize_boxes_and_labels_on_image_array(\n","                image_np_with_detections,\n","                detections['detection_boxes'],\n","                detections['detection_classes']+label_id_offset,\n","                detections['detection_scores'],\n","                category_index,\n","                use_normalized_coordinates=True,\n","                max_boxes_to_draw=5,\n","                min_score_thresh=.8,\n","                agnostic_mode=False)\n","    cv2.imwrite(str(i) + '.jpeg', image_np_with_detections)  # 保存检测结果"],"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:5 out of the last 5 calls to <function detect_fn at 0x7f5ec64a0440> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","WARNING:tensorflow:6 out of the last 6 calls to <function detect_fn at 0x7f5ec64a0440> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"id":"Gw46ziq1MjW5","executionInfo":{"status":"ok","timestamp":1635212846899,"user_tz":-480,"elapsed":377,"user":{"displayName":"yx IYATT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjkWQveQ9aeFabkZ0xN-od5GWsZF5pnqb-LIQcm=s64","userId":"12018810969794285660"}},"outputId":"91a05311-99f3-43b9-9eb6-906320eeead4"},"source":["from google.colab import files\n","for i in range(1, 8):\n","    files.download(str(i) + '.jpeg')  # 下载检测结果"],"execution_count":30,"outputs":[{"output_type":"display_data","data":{"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{}},{"output_type":"display_data","data":{"application/javascript":["download(\"download_4857def9-8d70-4d46-a85a-754cdf644eb2\", \"1.jpeg\", 177439)"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{}},{"output_type":"display_data","data":{"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{}},{"output_type":"display_data","data":{"application/javascript":["download(\"download_a5bc9c5c-0b44-4b80-a535-5c9dcdb2869b\", \"2.jpeg\", 157356)"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{}},{"output_type":"display_data","data":{"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{}},{"output_type":"display_data","data":{"application/javascript":["download(\"download_fd57f55c-a8aa-4db7-8a71-8d409367c1c9\", \"3.jpeg\", 143745)"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{}},{"output_type":"display_data","data":{"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{}},{"output_type":"display_data","data":{"application/javascript":["download(\"download_b9361e94-24f5-428f-8b26-b1dd579c9c56\", \"4.jpeg\", 61921)"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{}},{"output_type":"display_data","data":{"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{}},{"output_type":"display_data","data":{"application/javascript":["download(\"download_e5d86d5b-8e94-4372-ad1a-53a8341c857e\", \"5.jpeg\", 219422)"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{}},{"output_type":"display_data","data":{"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{}},{"output_type":"display_data","data":{"application/javascript":["download(\"download_7a17c887-2c74-42a8-baed-a7bd7269207f\", \"6.jpeg\", 209589)"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{}},{"output_type":"display_data","data":{"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{}},{"output_type":"display_data","data":{"application/javascript":["download(\"download_cb1a4274-f019-4dcd-968a-f54694d1b5f3\", \"7.jpeg\", 121736)"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"9aMxh4VnQSKe"},"source":["## 下载模型"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"id":"svMcH9j1KdjU","executionInfo":{"status":"ok","timestamp":1635212856662,"user_tz":-480,"elapsed":368,"user":{"displayName":"yx IYATT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjkWQveQ9aeFabkZ0xN-od5GWsZF5pnqb-LIQcm=s64","userId":"12018810969794285660"}},"outputId":"28f1cf1e-ee37-4acb-f68e-ccbe712f0ee5"},"source":["i = 1\n","while True:\n","    try:\n","        files.download('work-temp/workspace/models/ckpt-' + str(i) + '.data-00000-of-00001')\n","        files.download('work-temp/workspace/models/ckpt-' + str(i) + '.index')\n","    except:\n","        break\n","    i = i + 1"],"execution_count":31,"outputs":[{"output_type":"display_data","data":{"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{}},{"output_type":"display_data","data":{"application/javascript":["download(\"download_e4a08d45-7972-4633-9cda-2ad31fd973b9\", \"ckpt-1.data-00000-of-00001\", 10457085)"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{}},{"output_type":"display_data","data":{"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{}},{"output_type":"display_data","data":{"application/javascript":["download(\"download_459c0e8f-1a97-4bc7-a6d7-9e1e29bd2334\", \"ckpt-1.index\", 26244)"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{}},{"output_type":"display_data","data":{"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{}},{"output_type":"display_data","data":{"application/javascript":["download(\"download_92b9cd62-3c23-4d2c-be4d-49c67a9c83b0\", \"ckpt-2.data-00000-of-00001\", 20730782)"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{}},{"output_type":"display_data","data":{"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{}},{"output_type":"display_data","data":{"application/javascript":["download(\"download_18af7801-b40c-48d4-9059-50a3cad9e341\", \"ckpt-2.index\", 47999)"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{}},{"output_type":"display_data","data":{"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{}},{"output_type":"display_data","data":{"application/javascript":["download(\"download_753f21e7-1aa3-4bd7-9552-8378cb025a6b\", \"ckpt-3.data-00000-of-00001\", 20730782)"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{}},{"output_type":"display_data","data":{"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{}},{"output_type":"display_data","data":{"application/javascript":["download(\"download_0d27fad2-ecca-412f-8a3a-54dabecab30c\", \"ckpt-3.index\", 47999)"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{}}]}]}